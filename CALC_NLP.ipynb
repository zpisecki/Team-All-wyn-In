{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string\n",
    "import spacy\n",
    "import csv\n",
    "import tqdm \n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job description text cleaning functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(doc):\n",
    "    \"\"\"\n",
    "    Received a spacy doc object and cleans it\n",
    "    \"\"\"\n",
    "    doc = remove_stopwords(doc)\n",
    "    doc = remove_punctuation(doc)\n",
    "    doc = remove_numbers(doc)\n",
    "    doc = remove_nonalphabeticals(doc)\n",
    "    doc = convert_to_str(doc)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    \"\"\" removes stopwords from a doc \"\"\"\n",
    "    return [token for token in doc if not token.is_stop]\n",
    "\n",
    "def remove_punctuation(doc):\n",
    "    \"\"\" removes punctuation \"\"\"\n",
    "    return [token for token in doc if not token.is_punct]\n",
    "\n",
    "def remove_numbers(doc):\n",
    "    \"\"\" removes 'numbers' \"\"\"\n",
    "    return [token for token in doc if not token.like_num]\n",
    "\n",
    "def remove_nonalphabeticals(doc):\n",
    "    \"\"\" removes non-alphabeticals \"\"\"\n",
    "    return [token for token in doc if token.is_alpha]\n",
    "\n",
    "def remove_entities(doc, ents = ['PERSON', 'ORG', 'GPE']):\n",
    "    return [token for token in doc if token.ent_type_ not in ents]\n",
    "\n",
    "def convert_to_str(doc, lemmatize = True):\n",
    "    \"\"\" convert spacy doc objects to string \"\"\"\n",
    "    return [token.lemma_.lower() if lemmatize else token.text.lower() for token in doc]\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from local .csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'calc_scrape_final.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e62a7b518b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mjd_year_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mjd_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'calc_scrape_final.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mjd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'calc_scrape_final.csv'"
     ]
    }
   ],
   "source": [
    "jd_title = []\n",
    "jd_year_exp = []\n",
    "jd_text = []\n",
    "with open ('calc_scrape_final.csv') as df: \n",
    "    jd = csv.reader(df)\n",
    "    next(jd)\n",
    "    for i in jd: \n",
    "        jd_title.append((i[9]))\n",
    "        jd_year_exp.append((i[11]))\n",
    "        jd_text.append((i[18]))\n",
    "\n",
    "allwyn_title = []\n",
    "allwyn_year = []\n",
    "allwyn_jd_text = []\n",
    "with open('Allwyn Initial Job Description Input .csv') as df: \n",
    "    a_jd = csv.reader(df)\n",
    "    next(a_jd)\n",
    "    for i in a_jd: \n",
    "        allwyn_title.append((i[1]))\n",
    "        allwyn_year.append((i[3]))\n",
    "        allwyn_jd_text.append((i[6])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job description text cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_docs = nlp.pipe(jd_text) # text_corpus is simply a list of lists\n",
    "calc_jd = [clean_data(doc) for doc in c_docs] # the entire data, cleaned \n",
    "\n",
    "a_docs = nlp.pipe(allwyn_jd_text)\n",
    "clean_allwyn_jd = [clean_data(doc) for doc in a_docs] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pendas dataframe with clean job descriptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_rd = {\"c_job_title\": pd.Series(jd_title, dtype=\"string\"), \n",
    "           \"c_yesrs_of_experience\": pd.Series(jd_year_exp), \n",
    "           \"c_jd\": pd.Series(calc_jd, dtype=\"string\")}\n",
    "calc_df = pd.DataFrame(calc_rd)\n",
    "\n",
    "a_rd = {\"a_job_title\": pd.Series(allwyn_title, dtype=\"string\"), \n",
    "        \"a_yesrs_of_experience\": pd.Series(allwyn_year), \n",
    "        \"a_jd\": pd.Series(clean_allwyn_jd, dtype=\"string\")}\n",
    "a_df = pd.DataFrame(a_rd) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job description matching without using pendas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calc_jd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9687fd400413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mac_list_count0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#def exact_match(calc_jd, clean_allwyn_jd):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_jd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_allwyn_jd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_jd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calc_jd' is not defined"
     ]
    }
   ],
   "source": [
    "ac_list0 = []\n",
    "ac_list_count0 = []\n",
    "#def exact_match(calc_jd, clean_allwyn_jd): \n",
    "for i in range(len(calc_jd)): \n",
    "    a1 = clean_allwyn_jd[0]\n",
    "    s1 = set(calc_jd[i])\n",
    "    s2 = set(a1)\n",
    "    ac2 = list(s1.intersection(s2))\n",
    "    ac_list0 .append(ac2)\n",
    "    ac_count2 = len(ac2)\n",
    "    ac_list_count0.append(ac_count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
